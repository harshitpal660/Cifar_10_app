
from tensorflow import keras
(x_train,y_train),(x_test,y_test)=keras.datasets.cifar10.load_data()

import tensorflow as tf

print(tf.__version__)

from sklearn.model_selection import train_test_split
x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)

# normalization 
x_train=x_train/255
x_test=x_test/255
x_val=x_val/255

# One hot encoding
from tensorflow.keras.utils import to_categorical
y_train=to_categorical(y_train)
y_val=to_categorical(y_val)
y_test=to_categorical(y_test)

print(x_train.shape,y_train.shape)
print(x_test.shape,y_test.shape)
print(x_val.shape,y_val.shape)

base_model=keras.applications.ResNet50(include_top=False,weights="imagenet",input_shape=(32,32,3),classes=y_train.shape[1])

base_model.summary()

# Adding the final layers to the above base models where the actual classification is done in the dense layer
from tensorflow.keras.layers import Flatten
model = keras.Sequential()
model.add(base_model)
model.add(Flatten())
# model.summary()

model.summary()

import tensorflow
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dropout
# from tensorflow.keras.layers import Conv2D
# from tensorflow.keras.layers import MaxPooling2D
# model = tensorflow.keras.Sequential()
# model.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))
# model.add(MaxPooling2D())
model.add(Dense(1500,activation=('relu'),input_dim=512))
model.add(Dropout(0.5))
model.add(Dense(10,activation='softmax'))

model.summary()

batch_size=100
epochs=50
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=["accuracy"])
# early_stop=tensorflow.keras.callbacks.EarlyStopping(
#     monitor="val_loss",patience=3,
#     verbose=5,
#     mode="min",
# )

from keras.preprocessing.image import ImageDataGenerator
# Image Data Augmentation
train_generator=ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=0.2,shear_range=0.2)
val_generator=ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=0.2,shear_range=0.2)
test_generator=ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=0.2,shear_range=0.2)
                                  
# # Fitting the augmentation define above to the Data
train_generator.fit(x_train)
val_generator.fit(x_val)
test_generator.fit(x_test)


model.fit(train_generator.flow(x_train,y_train,batch_size=100),epochs=50,
         validation_data=val_generator.flow(x_val,y_val,batch_size=100))

import pandas as pd
loss=pd.DataFrame(model.history.history).plot()

import numpy as np
y_pred=model.predict(x_test)
y_pred=np.argmax(y_pred,axis=1)
y_pred

model.save('cifar.hdf5')
