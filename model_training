from tensorflow import keras
(x_train,y_train),(x_test,y_test)=keras.datasets.cifar10.load_data()
from sklearn.model_selection import train_test_split
x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)
# normalization 
x_train=x_train/255
x_test=x_test/255
x_val=x_val/255
# One hot encoding
from tensorflow.keras.utils import to_categorical
y_train=to_categorical(y_train)
y_val=to_categorical(y_val)
y_test=to_categorical(y_test)
print(x_train.shape,y_train.shape)
print(x_test.shape,y_test.shape)
print(x_val.shape,y_val.shape)
from keras.preprocessing.image import ImageDataGenerator
# Image Data Augmentation
train_generator=ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=.1)
val_generator=ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=.1)
test_generator=ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=.1)
                                  
# # Fitting the augmentation define above to the Data
train_generator.fit(x_train)
val_generator.fit(x_val)
test_generator.fit(x_test)
base_model=keras.applications.VGG19(include_top=False,weights="imagenet",input_shape=(32,32,3),classes=y_train.shape[1])

base_model.summary()

# Adding the final layers to the above base models where the actual classification is done in the dense layer
from tensorflow.keras.layers import Flatten
model = keras.Sequential()
model.add(base_model)
model.add(Flatten())
# model.summary()

import tensorflow
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dropout
# from tensorflow.keras.layers import Conv2D
# from tensorflow.keras.layers import MaxPooling2D
# model = tensorflow.keras.Sequential()
# model.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))
# model.add(MaxPooling2D())
# model.add(Flatten(input_shape=(32,32,3)))
model.add(Dense(1500,activation=('relu'),input_dim=512))
model.add(Dense(750,activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(10,activation='softmax'))

model.summary()

batch_size=100
epochs=50
model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=["accuracy"])
early_stop=tensorflow.keras.callbacks.EarlyStopping(
    monitor="val_loss",patience=3,
    verbose=5,
    mode="min",
)

model.fit(train_generator.flow(x_train,y_train,batch_size=batch_size),
                      epochs=epochs,
                      validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),callbacks=early_stop)


import pandas as pd
loss=pd.DataFrame(model.history.history).plot()

import numpy as np
y_pred=model.predict(x_test)
y_pred=np.argmax(y_pred,axis=1)
y_pred

np.unique(y_pred,return_counts=True)

from sklearn.metrics import accuracy_score,confusion_matrix
y_test=np.argmax(y_test,axis=1)
accuracy_score(y_test,y_pred)

confusion_matrix(y_test,y_pred,) 

from sklearn.metrics import accuracy_score,confusion_matrix
accuracy_score(y_test,y_pred)


model.save('Cifar.hdf5')
